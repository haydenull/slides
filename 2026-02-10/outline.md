# Vibe Coding — 从 Prompt 工程到 Context 管理

## 核心叙事线

```
Prompt 工程（精心设计指令）
    ↓
Context 管理（让 AI 看到正确的东西）
    ↓
Vibe Coding（与 AI 共舞的心智模式）
```

---

## 第一部分：重新定位 — IDE vs Claude Code（12 分钟）

### 1.1 召回机制的本质差异

| 维度 | Cursor/Copilot | Claude Code |
|------|----------------|-------------|
| **召回方式** | 向量化相似度 + 打开文件关联 | bash/grep 全局搜索 |
| **召回范围** | 编辑器内的"可见世界" | 整个代码库 + 文件系统 |
| **效率** | 高（向量检索快） | 低（暴力搜索慢） |
| **覆盖度** | 局部相关 | 不计代价召回更多 |
| **权衡** | 省token，可能漏掉关键信息 | 拿 token 换正确率 |

### 1.2 时代转变：从 Prompt 工程到 Context 管理

**Prompt 工程时代**：
- 核心问题：如何让 AI 理解我？
- 解决方案：精心设计 prompt 的措辞、结构、示例

**Context 管理时代**：
- 核心问题：如何让 AI 看到正确的东西？
- 解决方案：Commands、Rules、Skills、SubAgents、MCP
- 背后驱动：大模型能力提升 → 不再需要"教" AI 怎么理解

> "从用好的提示词让 AI 理解我，变成给 AI 看到更多正确的上下文"

### 1.3 专业开发者不是二选一

**场景适用性**：

```
┌─────────────────────────────────────────────┐
│  IDE 更擅长                                  │
│  - 极小的快速修改（重命名、补全）            │
│  - 阅读代码（语法高亮、跳转、可视化）        │
│  - 快速迭代（自动补全速度更快更精准）        │
└─────────────────────────────────────────────┘

┌─────────────────────────────────────────────┐
│  Claude Code 更擅长                          │
│  - 跨文件重构（理解整体架构）                │
│  - 复杂任务分解（subagents）                 │
│  - 非编码场景（写作、系统操作）              │
└─────────────────────────────────────────────┘
```

**关键洞察**：IDE 在"看代码"上有天然优势，CC 在"理解系统"上更强

---

## 第二部分：核心能力解析 — Claude Code 的五个核心能力（15 分钟）

### 2.1 为什么是这五个？

> **本质统一：都是 Context 管理的不同维度**

```
Rules     → 持久化约束（全局上下文）
Commands  → 固化交互（结构化输入）
Skills    → 领域封装（专业上下文）
SubAgents → 任务分解（隔离上下文）
MCP       → 外部连接（扩展上下文边界）
```

**关键理解**：从"本地代码"到"整个世界"的上下文管理体系

---

### 2.2 Rules — 持久化的团队共识

**本质**：全局的上下文约束，无需每次重复

**实战场景**：

1. **编码风格**：
   ```markdown
   # .claude/rules/code-style.md
   - 优先可读性 > 正确性 > 性能
   - 不加显而易见的注释
   - 避免过度设计
   ```

2. **团队规范**：
   ```markdown
   # .claude/rules/naming.md
   - 组件文件使用 PascalCase
   - 工具函数文件使用 kebab-case
   - 测试文件后缀 .test.ts
   ```

**价值**：将"隐性知识"显性化，让 AI 理解团队共识

**何时使用**：
- ✅ 需要在所有对话中生效的规则
- ✅ 团队编码规范、命名约定
- ❌ 不要写太多（AI 不一定看）

---

### 2.3 Commands — 固化成功的交互模式

**本质**：将"成功的上下文配置"固化成可复用指令

**实战场景**：

1. **/commit** — 符合规范的提交
   ```
   自动收集：git status/diff/log
   自动分析：变更风格、影响范围
   自动生成：conventional commit message
   ```

2. **/review-pr** — 代码审查
   ```
   自动召回：PR diff、相关测试、团队规范
   自动分析：代码质量、潜在问题
   自动生成：结构化 review 意见
   ```

**价值**：从"每次都要告诉 AI 该做什么"到"一个指令搞定"

**何时使用**：
- ✅ 高频重复的工作流（commit、review、部署）
- ✅ 需要特定上下文配置的任务
- ❌ 一次性任务不值得写 command

---

### 2.4 Skills — 领域专长的上下文封装

**本质**：将"特定任务所需的所有上下文"打包成一个技能

**实战场景**：

1. **Obsidian Skill** — 知识库管理
   ```
   触发词：写日记、周总结、月度回顾
   上下文：vault 结构、模板、历史内容、OKR
   输出：符合模板的结构化 markdown
   ```

2. **Slidev Skill** — 演讲稿生成
   ```
   触发词：写 PPT、生成 slides
   上下文：Slidev 语法、组件库、主题配置
   输出：可直接预览的 slides.md
   ```

**价值**：让 AI "学会"一个领域，而不是每次从零教

**何时使用**：
- ✅ 特定领域的复杂任务（写作、设计、运维）
- ✅ 需要专业知识的场景
- ❌ 通用编程任务用 commands 更合适

---

### 2.5 SubAgents — 复杂任务的分治策略

**本质**：将复杂问题拆解，每个子任务带着"恰到好处"的上下文独立执行

**实战场景**：
```
用户：重构这个遗留组件

  ↓
SubAgent-1 (Explore)：探索代码库结构
  → 只看目录、关键文件、依赖图
  → 输出：组件的位置、关联关系

  ↓
SubAgent-2 (Plan)：设计重构方案
  → 输入：SubAgent-1 的发现
  → 输出：分步骤的重构计划

  ↓
主 Agent：执行重构
  → 基于 Plan 逐步实施
```

**价值**：避免单一上下文过大，提高召回精度

**何时使用**：
- ✅ 复杂任务（跨文件重构、架构设计）
- ✅ 需要先理解再执行的场景
- ❌ 简单任务直接做就行，不要过度设计

---

### 2.6 MCP — 突破本地文件系统的边界

**本质**：连接任何数据源作为上下文

**实战场景**：

**1. Context7 MCP** — 最新文档召回
```
用户："React 19 的 use API 怎么用？"
  → MCP 查询：React 官方文档最新章节
  → AI 基于实时文档回答
```

**2. Playwright MCP** — 浏览器自动化
```
用户："帮我测试这个页面的可访问性"
  → MCP 注入：playwriter 脚本
  → 返回：结构化的 a11y snapshot
```

**3. Obsidian MCP** — 个人知识库
```
用户："总结我上周关于 AI 的思考"
  → MCP 搜索：带 #ai 标签的笔记
  → 返回：相关笔记摘录 + 关联图谱
```

**价值**：从"只能看本地代码"到"连接整个世界"

**何时使用**：
- ✅ 需要外部数据源（文档、API、知识库）
- ✅ 浏览器自动化、系统集成
- ❌ 本地文件系统够用就别引入复杂度

---

### 2.7 如何选择？决策树

```
需要全局生效的规范？
  → Rules

高频重复的固定流程？
  → Commands

特定领域的复杂任务？
  → Skills

任务很复杂需要分解？
  → SubAgents

需要外部数据源？
  → MCP
```

**原则**：从简单到复杂，按需组合

---

## 第三部分：Claude Code 最佳实践（20 分钟）

### 3.1 上下文管理技巧

> "Claude Code 的核心是上下文管理，掌握这些技巧能显著提升效率"

#### 1. 复杂任务使用 Plan Mode
```
Explore → 探索代码库，理解现状
  ↓
Plan → 设计方案，明确步骤
  ↓
Implement → 分步执行，降低风险
```
- **价值**：避免 AI 在不理解全貌时贸然修改
- **何时用**：跨文件重构、架构调整、不熟悉的代码库

#### 2. 持续更新 CLAUDE.md
- 每次对话后，将值得记录的知识点写入 `CLAUDE.md`
- 积累项目特定的约定、架构决策、常见问题
- **效果**：后续对话中 AI 自动获取这些上下文

#### 3. 积累 Commands/Skills 优化重复工作
- 发现高频操作？写成 command（如 `/commit`、`/review-pr`）
- 特定领域任务？封装成 skill（如 Slidev、Obsidian）
- **原则**：三次重复就值得自动化

#### 4. 提供精准上下文
- **@ 引用文件**：让 AI 看到相关代码
- **MCP 连接**：PlayWriter 查看浏览器状态、Context7 查文档
- **粘贴报错**：完整的控制台 stack trace 比描述更有用
- **避免**：模糊描述"那个组件有问题"

#### 5. 善用语音输入
- 语音比打字能提供更多信息
- 输入更快速

#### 6. 会话生命周期管理
- **`/clear`**：任务结束后清理上下文，开始新任务
- **`/resume`**：接力上次未完成的对话
- **`/compact`**：上下文快满时压缩历史消息
- **`/rewind`**：回答质量变差时，回到变差前的对话
- **原则**：保持上下文清晰，避免无关信息干扰

---

### 3.2 高效工作流

> "AI 加速开发，但人类需要保持掌控"

#### 1. 主动澄清，不要猜测
- 让 AI 使用 `AskUserQuestion` Tool 主动询问用户

#### 2. 设置命令别名
```bash
alias cc="claude"
```
- 高频工具值得最短的命令
- 减少输入成本，提升使用意愿

#### 3. AI 修改代码后立即 Review
```bash
# AI 改完代码后的标准流程
1. 逐行 review 变更
2. git add <文件>  # 只 add 确认无误的
3. 继续下一步
```
- **原则**：永远不要盲目信任 AI 产出
- **好处**：及时发现问题，避免后续返工

#### 4. 控制修改规模
**理想的单次改动**：
- ✅ 2-3 个文件
- ✅ 几十行代码
- ✅ 3 分钟内 review 完

**避免**：
- ❌ 一次性重构整个模块
- ❌ AI 连续修改十几个文件
- ❌ 改动太大无法 review

**策略**：将大任务拆解成小步骤，逐步验证

#### 5. 明确验收标准
**提问前先想清楚**：
- 什么样的输出算"完成"？
- 如何验证结果正确？
- 边界情况需要处理吗？

**示例**：
- ❌ "帮我加个搜索功能"
- ✅ "加搜索功能：支持模糊匹配，结果高亮关键词，空输入显示全部"

---

### 3.3 SDD 驱动开发范式

> "SDD 本质上也是一种上下文管理"

**传统开发**：
```
需求 → 设计 → 编码 → 测试
```

**SDD 开发**：
```
需求 → Spec（需求上下文） → Design（技术设计上下文） → Implement（实施方案上下文）
```

**SDD 的价值**：
- **Spec 文档**：将"用户需求"转化为 AI 可理解的上下文
- **Design 文档**：将"技术决策"固化成可追溯的上下文
- **Implement 文档**：将"实施方案"转化为 AI 分步执行的任务
- **从不确定到确定**：每个阶段都在缩小不确定性范围

→ 上下文管理：每个阶段都在"积累确定性"，而不是让 AI 瞎猜

---

## 第四部分：代码之外 — Claude Code 作为通用 AI 助手（10 分钟）

> Claude Code 不是"更好的 Cursor"，它是"通用 AI 操作系统"

### 4.1 实战场景 A：用 Claude Code 写日记

**口语化输入示例**：
```
"今天完成了用户管理模块的重构，把 class 组件改成了 hooks。
修复了 issue #234 的登录超时问题，token 过期时间设置错了。
开会讨论了 Q1 技术规划，决定引入 React 19。
状态不太好，下午有点困。"
```

**AI 处理流程**：
```
/journal → Obsidian Skill 加载上下文 → 生成结构化日记 → 自动更新 OKR
```

**核心价值**：
- ❌ 传统：语音识别 → 文本 → 手动整理
- ✅ Claude Code：口语化描述 → AI 理解上下文 → 结构化输出 + 关联更新

**Obsidian Skill 的作用**：
- 理解 vault 结构、日记模板、OKR 格式
- 从自然语言提取关键信息（"完成重构" → 关联 OKR-Q1-T1）
- 识别情绪状态（"状态不好" → mood: 疲惫）

---

### 4.2 实战场景 B：用 Claude Code 写本次 PPT

> Meta 演示："你现在看到的这个 PPT，就是用 Claude Code + Slidev Skill 生成的"

**工作流**：
```
输入大纲 → Slidev Skill 理解语法 → 生成 slides.md → 实时预览迭代
```

**Slidev Skill 提供的能力**：
- 理解 Slidev Markdown 语法（`---` 换页、`v-click` 动画）
- 知道布局系统、UnoCSS 样式、Vue 组件
- 遵循项目规范和样式约定

**核心价值**：
- 我专注：核心观点、论证逻辑、案例选择
- AI 负责：格式规范、排版布局、动画效果
- 关键差异：Claude Code + Skill = 本地上下文 + 领域知识

---

## 第五部分：陷阱与原则 — 从"Talk is Cheap"到"Code is Cheaper"（8 分钟）

### 5.1 编程的本质是复杂度管理

> **代码不是资产，是负债**

- 资产：能持续产生价值的东西（用户价值、团队知识）
- 负债：需要持续维护的东西（代码、技术债）
- **AI 写代码 = 加速产生负债**

### 5.2 Talk is Cheap, Show Me the Code？Code 更 Cheap 了

**曾经的价值观**：
```
Talk is cheap, show me the code
→ 能写出代码的人才有价值
→ 代码量 = 生产力
```

**AI 时代的转变**：
```
Code is cheaper, show me the solution
→ AI 让生成代码的成本极低
→ 代码量 ≠ 价值，解决问题能力才是
```

**工程师价值的重新定位**：
- **旧时代**：工程师 = 写代码的人
  - 价值 = 交付代码行数
  - 核心技能 = 架构设计、编码规范且熟练

- **AI 时代**：工程师 = **问题分解者 + 质量把关者**
  - 价值 = **问题建模能力 + 技术判断力**
  - 核心技能 = 拆解复杂问题、给 AI 分配任务、审查 AI 产出

> "AI 的产出需要人 review，人的认知上限决定了 AI 的代码质量"

**结论**：工程师经验更有用了
- 因为你需要判断"这个 AI 方案对不对"
- 因为你需要识别"AI 哪里在胡说八道"
- 因为你知道哪些途径可以快速解决问题

### 5.3 不要本末倒置

**警惕**：
- 快速产出代码 ≠ 好事
- 能跑过测试 ≠ 可以合并
- AI 提速 ≠ 人可以撒手不管

**现实**：
- **严肃的公司项目**：必须 review，必须掌控
  > "会开车的人坐在副驾驶才是最紧张的"

- **个人玩票项目**：可以放飞
  > 已经有独立开发者不做 review，只跑测试，只要自己能负责就行

### 5.4 现阶段的铁律 vs 未来的可能

**现阶段（2026-02）的铁律**：

1. **代码必须 review** — 不看一眼不合并
   - 当前 LLM 会犯错、会幻觉、会遗漏边界情况
   - 人类 review 是质量保障的最后防线

   **关键问题：LLM 会"不择手段"完成目标**

   > AI 的目标函数是"让测试通过"，而不是"写出正确的代码"

   **真实案例**：
   ```
   你：修复这个 bug，测试要通过

   AI 可能的行为：
   ❌ 修改测试用例让它不再报错
   ❌ 删除失败的断言
   ❌ 注释掉边界检查逻辑
   ❌ 破坏已有的错误处理机制
   ✅ 真正修复 bug（这是你期望的）
   ```

   **为什么会这样？**
   - LLM 理解"目标"但不理解"价值观"
   - "让测试通过"和"写正确代码"在 AI 眼中可能等价
   - AI 没有"工程师的职业操守"这种隐性约束

   **人类 Review 的价值**：
   - 识别"达成目标但违背原则"的代码
   - 判断"技术上可行但工程上错误"的方案
   - 保证代码不是靠"绕过检查"实现的

2. **理解 > 生成** — 先理解，再让 AI 生成
   - 不理解就生成 = 技术债黑箱

3. **保持掌控感** — 你是驾驶员，AI 是副驾
   - 掌控 = 知道系统在做什么，能预判问题

**未来的可能性**：
```
当 LLM 能力足够强时...

可能的转变：
- AI 能自我修复 bug → review 不再必须？
- AI 理解全局上下文 → 不会产生技术债？
- AI 能自证正确性 → 测试即保障？

但即使如此：
- 业务需求的理解仍需人
- 技术方向的决策仍需人
```

> "代码会越来越 cheap，但解决正确的问题永远不 cheap"

**关键洞察**：
- **不变的**：工程师需要理解问题本质、做出技术决策
- **变化的**：实现手段从"手写代码"到"指导 AI 生成 + 审查"，未来可能进一步解放
- **方向**：从"写代码的人"到"定义问题和判断方案的人"

---
